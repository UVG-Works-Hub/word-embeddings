{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2898aaea",
   "metadata": {},
   "source": [
    "# Laboratorio 8 - Word Embeddings\n",
    "## <font size=4> *CC3092 - Deep Learning y Sistemas Inteligentes*, 2024 </font>\n",
    "## <font size=3 color='gray'> Samuel Chamale y Adrian Rodriguez</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666bbfc5",
   "metadata": {},
   "source": [
    "### Generar Embeddings con Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23556a2b0d70ade4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T21:49:18.787896Z",
     "start_time": "2024-10-11T21:49:18.672526Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0248f2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chama\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar recursos de NLTK (si no se han descargado previamente)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7defb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos desde el archivo de texto\n",
    "# Se intentó con 'utf-8' pero no funcionó\n",
    "# al parecer el archivo está codificado en 'latin1', fue coincidencia haberlo descubierto,\n",
    "# probé con varios y este fue el único que funcionó (e.g. 'utf-8', 'utf-16', 'utf-32', 'ascii', 'cp1252')\n",
    "with open('reviews_data.txt', 'r', encoding='latin1') as file:\n",
    "    documents = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22d536b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 28957 líneas mal formadas (esto significa un porcentaje de: 11.30%)\n"
     ]
    }
   ],
   "source": [
    "# Lista para almacenar solo las reseñas\n",
    "reviews = []\n",
    "malformed_lines = 0\n",
    "\n",
    "for line in documents:\n",
    "    sections = line.strip().split('\\t')\n",
    "    if len(sections) == 3:\n",
    "        date, title, review = sections\n",
    "        reviews.append(review)\n",
    "    else:\n",
    "        malformed_lines += 1\n",
    "\n",
    "print(f\"Se encontraron {malformed_lines} líneas mal formadas (esto significa un porcentaje de: {malformed_lines/len(documents)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200d64a74abbd226",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocesar los documentos AKA reseñas\n",
    "def preprocess(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizar\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bca4acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar preprocesamiento a todos los documentos\n",
    "processed_docs = [preprocess(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d1232ab40147d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:32:47.086120Z",
     "start_time": "2024-10-11T22:31:23.270763Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=processed_docs,\n",
    "    vector_size=100,  # Tamaño del vector de embeddings\n",
    "    window=5,         # Tamaño de la ventana de contexto\n",
    "    min_count=5,      # Ignorar palabras con frecuencia menor a 5\n",
    "    workers=4,        # Número de hilos para el entrenamiento\n",
    "    sg=0              # Uso de CBOW (sg=1 para Skip-gram)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2df8cfc14093d69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:33:37.483030Z",
     "start_time": "2024-10-11T22:33:37.430992Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294622642, 415389570)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(processed_docs, total_examples=len(processed_docs), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5092b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "# model.save(\"word2vec_review_data.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2a3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado\n",
    "# model = Word2Vec.load(\"word2vec_review_data.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182fff2",
   "metadata": {},
   "source": [
    "### Encontrar las 10 Palabras Más Similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e23963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras similares a 'street': ['road', 'streetthe', 'rd', 'steet', 'streetit', 'streeti', 'streetits', 'st', 'stree', 'streeta']\n",
      "Palabras similares a 'good': ['decent', 'great', 'terrific', 'goodthe', 'nice', 'excellent', 'fantastic', 'fab', 'superb', 'excellentthe']\n",
      "Palabras similares a 'dog': ['dogs', 'child', 'baby', 'pup', 'cat', 'pet', 'companion', 'doll', 'toddler', 'swimsuit']\n",
      "Palabras similares a 'mother': ['father', 'niece', 'mom', 'mum', 'sisterinlaw', 'cousin', 'daughter', 'neice', 'brother', 'nephew']\n",
      "Palabras similares a 'bed': ['beds', 'bedthe', 'sofabed', 'mattress', 'daybed', 'bed2', 'bedsour', 'hideabed', 'bedwe', 'bedsclean']\n"
     ]
    }
   ],
   "source": [
    "# Lista de palabras objetivo\n",
    "target_words = ['street', 'good', 'dog', 'mother', 'bed']\n",
    "\n",
    "# Diccionario para almacenar las palabras similares\n",
    "similar_words = {}\n",
    "\n",
    "for word in target_words:\n",
    "    if word in model.wv:\n",
    "        similar = model.wv.most_similar(word, topn=10)\n",
    "        similar_words[word] = [w for w, score in similar]\n",
    "        print(f\"Palabras similares a '{word}': {similar_words[word]}\")\n",
    "    else:\n",
    "        print(f\"La palabra '{word}' no se encuentra en el vocabulario.\")\n",
    "        similar_words[word] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
